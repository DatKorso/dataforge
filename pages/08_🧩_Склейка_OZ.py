from __future__ import annotations

import io
from dataclasses import dataclass, field

import pandas as pd
import streamlit as st
from dataforge.matching import search_matches
from dataforge.matching_helpers import add_merge_fields
from dataforge.ui import setup_page

setup_page(title="DataForge ‚Äî –°–∫–ª–µ–π–∫–∞ OZ", icon="üß©")

DEFECT_PREFIX = "–ë—Ä–∞–∫SH"


@dataclass
class MergeConfig:
    md_token: str | None = None
    md_database: str | None = None
    filter_no_defect: bool = True
    filter_unique_sizes: bool = True
    limit_per_input: int = 0
    selected_cols: list[str] = field(default_factory=lambda: [
        "wb_sku",
        "oz_sku",
        "oz_vendor_code",
        "merge_code",
        "merge_color",
    ])


def parse_input(text: str) -> list[str]:
    tokens = [t.strip() for t in text.replace(",", " ").split()]
    return [t for t in tokens if t]


st.title("üß© –°–∫–ª–µ–π–∫–∞ –∫–∞—Ä—Ç–æ—á–µ–∫ OZ")
st.caption("–°–≤—è–∑—ã–≤–∞–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ OZ –º–µ–∂–¥—É —Å–æ–±–æ–π –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É –∞–ª–≥–æ—Ä–∏—Ç–º—É (–±–∞–∑–æ–≤—ã–π: –æ–±—â–∏–π wb_sku).")


md_token = st.session_state.get("md_token") or st.secrets.get("md_token") if hasattr(st, "secrets") else None
md_database = st.session_state.get("md_database") or st.secrets.get("md_database") if hasattr(st, "secrets") else None

if not md_token:
    st.warning("MD —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ù–∞—Å—Ç—Ä–æ–π–∫–∏.")


with st.form(key="oz_merge_form"):
    col1, col2 = st.columns([1, 1])
    with col1:
        merge_algo = st.selectbox(
            "–ê–ª–≥–æ—Ä–∏—Ç–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è",
            options=[("–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –ø–æ –æ–±—â–µ–º—É WB –∞—Ä—Ç–∏–∫—É–ª—É", "wb_by_sku")],
            format_func=lambda x: x[0] if isinstance(x, tuple) else x,
            key="oz_merge_algo",
        )

    with col2:
        st.number_input(
            "–õ–∏–º–∏—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (0 ‚Äî –±–µ–∑ –ª–∏–º–∏—Ç–∞)",
            min_value=0,
            max_value=10000,
            value=int(st.session_state.get("oz_merge_limit", 0)),
            key="oz_merge_limit",
        )

    st.text_area(
        "–°–ø–∏—Å–æ–∫ WB SKU",
        value=st.session_state.get("oz_merge_input_text", ""),
        height=140,
        help="–í—Å—Ç–∞–≤—å—Ç–µ —Å–ø–∏—Å–æ–∫ wb_sku —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –∏–ª–∏ –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É.",
        key="oz_merge_input_text",
    )

    st.checkbox("–ë–µ–∑ –±—Ä–∞–∫–∞ –û–∑–æ–Ω", key="oz_merge_filter_no_defect", help="–ò—Å–∫–ª—é—á–∏—Ç—å oz_vendor_code –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è –Ω–∞ –ë—Ä–∞–∫SH")
    st.checkbox("–ë–µ–∑ –¥—É–±–ª–µ–π —Ä–∞–∑–º–µ—Ä–æ–≤", key="oz_merge_filter_unique_sizes", help="–û—Å—Ç–∞–≤–ª—è—Ç—å –ø–æ –æ–¥–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é —Ä–∞–∑–º–µ—Ä–∞ —Å –Ω–∞–∏–≤—ã—Å—à–∏–º match_score")

    submitted = st.form_submit_button("–°–∫–ª–µ–∏—Ç—å", type="primary")

if submitted:
    if not md_token:
        st.error("MD —Ç–æ–∫–µ–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ù–∞—Å—Ç—Ä–æ–π–∫–∏.")
        st.stop()

    text_value = st.session_state.get("oz_merge_input_text", "")
    values = parse_input(text_value)
    if not values:
        st.warning("–í–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω WB SKU.")
        st.stop()

    if len(values) > 500:
        st.info("–ü–µ—Ä–µ–¥–∞–Ω–æ –º–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏–π; –æ–ø–µ—Ä–∞—Ü–∏—è –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è.")

    try:
        with st.spinner("–ü–æ–∏—Å–∫ OZ –∫–∞—Ä—Ç–æ—á–µ–∫ –ø–æ WB SKU..."):
            df = search_matches(
                values,
                input_type="wb_sku",
                limit_per_input=(None if int(st.session_state.get("oz_merge_limit", 0)) <= 0 else int(st.session_state.get("oz_merge_limit", 0))),
                md_token=md_token,
                md_database=md_database,
            )

        # Apply defect filter
        if st.session_state.get("oz_merge_filter_no_defect", True) and "oz_vendor_code" in df.columns:
            starts_with_brak = df["oz_vendor_code"].fillna("").astype(str).str.startswith(DEFECT_PREFIX)
            df = df.loc[~starts_with_brak]

        # Deduplicate sizes similar to existing page
        if st.session_state.get("oz_merge_filter_unique_sizes", True):
            from dataforge.matching_helpers import dedupe_sizes

            df = dedupe_sizes(df, input_type="wb_sku")

        # Add merge fields
        df = add_merge_fields(df, wb_sku_col="wb_sku", oz_vendor_col="oz_vendor_code")

        st.session_state["oz_merge_result"] = df
        # collect invalid oz_vendor_code rows for highlighting
        if "oz_vendor_code" in df.columns:
            invalid_mask = ~df["oz_vendor_code"].astype(str).str.contains("-", regex=False)
            st.session_state["oz_merge_invalid_oz_vendor"] = df.loc[invalid_mask]
        else:
            st.session_state["oz_merge_invalid_oz_vendor"] = pd.DataFrame()
    except Exception as exc:
        st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ/–æ–±—Ä–∞–±–æ—Ç–∫–µ: ")
        st.exception(exc)

df_show: pd.DataFrame = st.session_state.get("oz_merge_result", pd.DataFrame())

if df_show.empty:
    st.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç –ø–æ–∫–∞–∑–∞–Ω—ã –∑–¥–µ—Å—å –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è '–°–∫–ª–µ–∏—Ç—å'.")
    st.stop()

cols_default = [
    "wb_sku",
    "oz_sku",
    "oz_vendor_code",
    "merge_code",
    "merge_color",
    "match_score",
]

cols_to_show = [c for c in st.session_state.get("oz_merge_selected_cols", cols_default) if c in df_show.columns]
if not cols_to_show:
    cols_to_show = [c for c in cols_default if c in df_show.columns]

st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–∫–ª–µ–π–∫–∏ OZ")
st.dataframe(df_show[cols_to_show], width="stretch", height=600)

csv_buf = io.StringIO()
df_show[cols_to_show].to_csv(csv_buf, index=False)
st.download_button(
    "–°–∫–∞—á–∞—Ç—å CSV",
    data=csv_buf.getvalue().encode("utf-8"),
    file_name="oz_merge.csv",
    mime="text/csv",
)
