from __future__ import annotations

import io
import json
from pathlib import Path
from typing import Any

import pandas as pd
import streamlit as st
from dataforge.db import get_connection
from dataforge.imports.assemblers import (
    assemble_ozon_products_full,
    assemble_wb_prices,
    assemble_wb_products,
)
from dataforge.imports.google_sheets import (
    check_access as gs_check_access,
)
from dataforge.imports.google_sheets import (
    dedup_by_wb_sku_first as gs_dedup,
)
from dataforge.imports.google_sheets import (
    read_csv_first_sheet as gs_read_csv,
)
from dataforge.imports.loader import load_dataframe, load_dataframe_partitioned
from dataforge.imports.reader import read_any
from dataforge.imports.registry import ReportSpec, get_registry
from dataforge.imports.validator import ValidationResult, normalize_and_validate
from dataforge.secrets import save_secrets
from dataforge.ui import setup_page
from dataforge.utils import filter_df_by_brands, parse_brand_list

setup_page(title="DataForge", icon="üõ†Ô∏è")
st.title("üì• –ò–º–ø–æ—Ä—Ç —Ñ–∞–π–ª–æ–≤")
st.caption(
    "–ó–∞–≥—Ä—É–∑–æ—á–Ω—ã–π —Ö–∞–± –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Ç–∞–±–ª–∏—Ü –ë–î. –î–æ–±–∞–≤–ª—è–π—Ç–µ –æ—Ç—á—ë—Ç—ã –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤ –∏ –∑–∞–≥—Ä—É–∂–∞–π—Ç–µ –≤ MotherDuck."
)

REGISTRY = get_registry()
SPEC_OPTIONS = {spec.name: spec.id for spec in REGISTRY.values()}

report_name = st.selectbox("–¢–∏–ø –æ—Ç—á—ë—Ç–∞", options=list(SPEC_OPTIONS.keys()))
report_id = SPEC_OPTIONS[report_name]
spec: ReportSpec = REGISTRY[report_id]

st.info(spec.description)

# Define _arrow_safe early so it can be used in all branches
def _arrow_safe(df: pd.DataFrame) -> pd.DataFrame:
    """Sanitize a DataFrame to avoid Arrow serialization issues in Streamlit.

    - For object columns, convert bytes/bytearray to UTF-8 strings
    - Cast mixed-type object columns to strings, preserving NaN as None
    """
    if df is None or df.empty:
        return df
    out = df.copy()
    for c in out.columns:
        s = out[c]
        if s.dtype == object:
            def _to_str(x: Any) -> Any:
                if x is None or (isinstance(x, float) and pd.isna(x)):
                    return None
                if isinstance(x, (bytes, bytearray)):
                    try:
                        return x.decode("utf-8", errors="replace")
                    except Exception:
                        return str(x)
                if isinstance(x, str):
                    return x
                return str(x)

            out[c] = s.map(_to_str)
    return out


def _select_barcode(raw: Any, prefer_last: bool = False) -> str | None:
    """Pick first/last non-empty barcode from JSON text or iterable."""
    if raw in (None, ""):
        return None

    if isinstance(raw, (list, tuple)):
        candidates = list(raw)
    else:
        candidates: list[Any]
        parsed: Any = None
        if isinstance(raw, str):
            try:
                parsed = json.loads(raw)
            except (TypeError, json.JSONDecodeError):
                parsed = None
        if isinstance(parsed, list):
            candidates = parsed
        elif parsed not in (None, ""):
            candidates = [parsed]
        elif isinstance(raw, str):
            candidates = [part.strip() for part in raw.split(";")]
        else:
            return None

    cleaned = [str(item).strip() for item in candidates if str(item).strip()]
    if not cleaned:
        return None
    return cleaned[-1] if prefer_last else cleaned[0]


# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤
punta_collection: str | None = None
if report_id == "punta_barcodes":
    punta_collection = st.text_input(
        "–ö–æ–ª–ª–µ–∫—Ü–∏—è",
        value=st.session_state.get("punta_collection", ""),
        help="–£–∫–∞–∂–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏. –ü–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π –¥–∞–Ω–Ω—ã–µ —ç—Ç–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –±—É–¥—É—Ç –æ—á–∏—â–µ–Ω—ã.",
    )
    st.session_state["punta_collection"] = punta_collection

uploaded = None
gs_url: str | None = None
if report_id != "punta_google":
    uploaded = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª(—ã) –æ—Ç—á—ë—Ç–∞",
        type=spec.allowed_extensions,
        accept_multiple_files=spec.multi_file,
        help=(
            "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è .csv –∏ .xlsx (Excel). –î–ª—è –ø–æ–ª–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ Ozon –¥–æ–ø—É—Å—Ç–∏–º–∞ –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤."
        ),
    )
else:
    # –û–¥–∏–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ Google Sheets ‚Äî —Å—Å—ã–ª–∫–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ secrets.toml
    def _sget_secret(key: str) -> str | None:
        try:
            return st.secrets[key]  # type: ignore[index]
        except Exception:
            return None

    gs_url = st.text_input(
        "–°—Å—ã–ª–∫–∞ –Ω–∞ Google Sheets",
        value=st.session_state.get("punta_google_url") or _sget_secret("punta_google_url") or "",
        placeholder="https://docs.google.com/spreadsheets/d/.../edit?usp=sharing",
        help="–í—Å—Ç–∞–≤—å—Ç–µ –ø—É–±–ª–∏—á–Ω—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–≤—ã–π –ª–∏—Å—Ç. 2-—è —Å—Ç—Ä–æ–∫–∞ –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–∞.",
    )
    st.session_state["punta_google_url"] = gs_url
    cols_gs = st.columns(3)
    with cols_gs[0]:
        if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å—Å—ã–ª–∫—É"):
            save_secrets({"punta_google_url": gs_url})
            st.success("–°—Å—ã–ª–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ .streamlit/secrets.toml")
    with cols_gs[1]:
        if st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø"):
            with st.spinner("–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É..."):
                ok, msg, df_prev = gs_check_access(gs_url)
            if ok:
                st.success(msg)
                if df_prev is not None and not df_prev.empty:
                    st.caption("–ü—Ä–µ–≤—å—é –ø–µ—Ä–≤—ã—Ö 10 —Å—Ç—Ä–æ–∫")
                    st.dataframe(_arrow_safe(df_prev.head(10)), width="stretch")
            else:
                st.error(msg)
    with cols_gs[2]:
        st.caption("–ò–º–ø–æ—Ä—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–º–µ–Ω–∏—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ç–∞–±–ª–∏—Ü—ã punta_google")


with st.expander("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–º–ø–æ—Ä—Ç–∞", expanded=False):
    if report_id != "punta_google":
        col1, col2, col3 = st.columns(3)
        with col1:
            delim_label = st.selectbox(
                "–†–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å (CSV)",
                options=["–ê–≤—Ç–æ", "–ó–∞–ø—è—Ç–∞—è ,", "–¢–æ—á–∫–∞ —Å –∑–∞–ø—è—Ç–æ–π ;", "–¢–∞–±—É–ª—è—Ü–∏—è \t"],
                index=0,
            )
        with col2:
            encoding = st.selectbox("–ö–æ–¥–∏—Ä–æ–≤–∫–∞", options=["utf-8", "cp1251", "auto"], index=0)
        with col3:
            header_row = st.number_input("–°—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤", min_value=1, value=spec.header_row + 1)

        clear_table = st.checkbox(
            "–û—á–∏—â–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π",
            value=True,
            help="–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç –ø–æ–ª–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤)",
        )
        if report_id == "punta_barcodes":
            st.caption("–î–ª—è Punta –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –∫ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏.")
    else:
        st.caption("–î–ª—è Punta Google –¥–∞–Ω–Ω—ã–µ —á–∏—Ç–∞—é—Ç—Å—è –∏–∑ Google Sheets; 2-—è —Å—Ç—Ä–æ–∫–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è; –∏–º–ø–æ—Ä—Ç –≤—Å–µ–≥–¥–∞ –∑–∞–º–µ–Ω—è–µ—Ç —Ç–∞–±–ª–∏—Ü—É.")
        # Placeholders to avoid UnboundLocalError below for non-GS branches
        delim_label = "–ê–≤—Ç–æ"
        encoding = "utf-8"
        header_row = spec.header_row + 1
        clear_table = True

def _ext_from_name(name: str) -> str:
    return Path(name).suffix.lstrip(".").lower()


def _delimiter_value(label: str) -> str | None:
    if label.startswith("–ê–≤—Ç–æ"):
        return None
    if "," in label:
        return ","
    if ";" in label:
        return ";"
    if "\t" in label:
        return "\t"
    return None


MAX_SIZE = 200 * 1024 * 1024  # 200MB

preview_col, import_col = st.columns([1, 1])

has_input = False
if report_id == "punta_google":
    has_input = bool(gs_url)
else:
    if spec.multi_file:
        has_input = isinstance(uploaded, list) and len(uploaded) > 0
    else:
        has_input = uploaded is not None

if has_input and report_id != "punta_google":
    size = getattr(uploaded, "size", None)
    if spec.multi_file:
        total_size = sum(getattr(f, "size", 0) or 0 for f in uploaded)
        if total_size > MAX_SIZE:
            st.error("–°—É–º–º–∞—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–æ–≤ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º—É–º 200MB.")
        else:
            st.write(f"–í—ã–±—Ä–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(uploaded)}; —Å—É–º–º–∞—Ä–Ω–æ {total_size} –±–∞–π—Ç")
    else:
        if size and size > MAX_SIZE:
            st.error("–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä 200MB.")
        else:
            st.write(f"–§–∞–π–ª: {uploaded.name} ‚Äî {size or 0} –±–∞–π—Ç")

    with preview_col:
        if st.button("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è", type="primary"):
            try:
                if spec.assembler:
                    with st.spinner("–°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞(–æ–≤)..."):
                        if spec.assembler == "ozon_products_full":
                            df_src = assemble_ozon_products_full(uploaded)
                        elif spec.assembler == "wb_products":
                            df_src = assemble_wb_products(uploaded)
                        elif spec.assembler == "wb_prices":
                            files = uploaded if isinstance(uploaded, list) else [uploaded]
                            df_src = assemble_wb_prices(files)
                        else:
                            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Å–±–æ—Ä—â–∏–∫ –¥–ª—è –æ—Ç—á—ë—Ç–∞: {spec.assembler}")
                else:
                    ext = _ext_from_name(uploaded.name)
                    delimiter = _delimiter_value(delim_label)
                    enc = None if encoding == "auto" else encoding
                    with st.spinner("–ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞..."):
                        df_src = read_any(
                            uploaded, ext, delimiter=delimiter, encoding=enc, header_row=int(header_row) - 1
                        )

                # –ü–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –¥–ª—è –æ—Ç—á—ë—Ç–∞ Punta
                if report_id == "punta_barcodes":
                    if not punta_collection:
                        st.warning("–£–∫–∞–∂–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª—è '–ö–æ–ª–ª–µ–∫—Ü–∏—è' –ø–µ—Ä–µ–¥ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–æ–º.")
                        st.stop()
                    df_src = df_src.copy()
                    # –í—Å–µ–≥–¥–∞ –ø–æ–¥—Å—Ç–∞–≤–ª—è–µ–º –µ–¥–∏–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ; –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∫–æ–ª–æ–Ω–∫–∏
                    df_src["–ö–æ–ª–ª–µ–∫—Ü–∏—è"] = punta_collection

                st.session_state["last_src_preview"] = df_src.head(5)
                st.dataframe(_arrow_safe(df_src.head(10)), width="stretch")

                with st.spinner("–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è..."):
                    vr: ValidationResult = normalize_and_validate(df_src, spec)

                # Apply brand filter (if configured and applicable)
                def _sget(key: str) -> str | None:
                    try:
                        return st.secrets[key]  # type: ignore[index]
                    except Exception:
                        return None

                brand_raw = st.session_state.get("brand_whitelist") or _sget("brand_whitelist")
                allowed_brands = parse_brand_list(brand_raw)

                df_norm = vr.df_normalized
                if spec.id == "wb_products" and "barcodes" in df_norm.columns:
                    df_norm = df_norm.copy()
                    df_norm["primary_barcode"] = df_norm["barcodes"].map(
                        lambda v: _select_barcode(v, prefer_last=True)
                    )
                df_filtered = (
                    filter_df_by_brands(df_norm, allowed_brands)
                    if ("brand" in df_norm.columns and allowed_brands)
                    else df_norm
                )

                st.session_state["norm_df"] = df_filtered
                st.session_state["norm_errors"] = vr.errors

                st.subheader("–°–≤–æ–¥–∫–∞")
                m1, m2, m3 = st.columns(3)
                m1.metric("–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", vr.rows_total)
                m2.metric("–í–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫", vr.rows_valid)
                m3.metric("–û—à–∏–±–æ–∫", len(vr.errors))

                if "brand" in df_norm.columns and allowed_brands:
                    st.info(
                        f"–ü—Ä–∏–º–µ–Ω—ë–Ω —Ñ–∏–ª—å—Ç—Ä –±—Ä–µ–Ω–¥–æ–≤ (–≤ —Å–ø–∏—Å–∫–µ: {len(allowed_brands)}). "
                        f"–ö –∑–∞–≥—Ä—É–∑–∫–µ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞: {len(df_filtered)} —Å—Ç—Ä–æ–∫."
                    )

                if vr.errors:
                    st.warning("–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –æ—à–∏–±–∫–∏. –°—Ç—Ä–æ–∫–∏ —Å –æ—à–∏–±–∫–∞–º–∏ –±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ.")
                    st.dataframe(_arrow_safe(pd.DataFrame(vr.errors)), width="stretch")

                    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫ –≤ —Ñ–∞–π–ª (—Ç–æ–ª—å–∫–æ –¥–ª—è Punta)
                    if report_id == "punta_barcodes":
                        from datetime import datetime
                        from pathlib import Path as _Path

                        log_dir = _Path("logs")
                        log_dir.mkdir(exist_ok=True)
                        ts = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
                        log_path = log_dir / f"punta_barcodes_{ts}.log"
                        lines = [
                            f"row={e.get('row')} | errors={e.get('errors')}" for e in vr.errors
                        ]
                        log_path.write_text("\n".join(lines), encoding="utf-8")
                        st.info(f"–õ–æ–≥ –æ—à–∏–±–æ–∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {log_path}")

                st.subheader("–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ø—Ä–µ–≤—å—é)")
                st.dataframe(_arrow_safe(df_filtered.head(20)), width="stretch")

                csv_buf = io.StringIO()
                vr.df_normalized.to_csv(csv_buf, index=False)
                st.download_button(
                    "–°–∫–∞—á–∞—Ç—å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π CSV",
                    data=csv_buf.getvalue().encode("utf-8"),
                    file_name=f"{spec.table}_normalized.csv",
                    mime="text/csv",
                )
            except Exception as exc:  # noqa: BLE001
                st.exception(exc)

    with import_col:
        if st.button("–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –ë–î", disabled="norm_df" not in st.session_state):
            try:
                df_ready: pd.DataFrame = st.session_state.get("norm_df", pd.DataFrame())
                if df_ready.empty:
                    st.error("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä.")
                else:
                    def _sget(key: str) -> str | None:
                        try:
                            return st.secrets[key]  # type: ignore[index]
                        except Exception:
                            return None

                    md_token = st.session_state.get("md_token") or _sget("md_token")
                    md_database = st.session_state.get("md_database") or _sget("md_database")
                    if not md_token:
                        st.warning("MD —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ù–∞—Å—Ç—Ä–æ–π–∫–∏.")

                    # Re-apply brand filter using the latest settings just before import (safety net)
                    brand_raw = st.session_state.get("brand_whitelist") or _sget("brand_whitelist")
                    allowed_brands = parse_brand_list(brand_raw)
                    if "brand" in df_ready.columns and allowed_brands:
                        df_ready = filter_df_by_brands(df_ready, allowed_brands)

                    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –≤ MotherDuck..."):
                        if report_id == "punta_barcodes":
                            # –î–ª—è Punta –≤—Å–µ–≥–¥–∞ –∑–∞–º–µ–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
                            coll = st.session_state.get("punta_collection")
                            if not coll:
                                st.error("–ù–µ —É–∫–∞–∑–∞–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏.")
                                st.stop()
                            msg = load_dataframe_partitioned(
                                df_ready,
                                table=spec.table,
                                partition_field="collection",
                                partition_value=str(coll),
                                md_token=md_token,
                                md_database=md_database,
                            )
                        else:
                            msg = load_dataframe(
                                df_ready,
                                table=spec.table,
                                md_token=md_token,
                                md_database=md_database,
                                replace=clear_table,
                            )
                    st.success(msg)
            except Exception as exc:  # noqa: BLE001
                st.exception(exc)

elif report_id == "punta_google":
    # –ü–æ—Ç–æ–∫ –¥–ª—è Punta Google (–±–µ–∑ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ —Ñ–∞–π–ª–æ–≤)
    with preview_col:
        if st.button("–ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä", type="primary", disabled=not gs_url):
            try:
                with st.spinner("–ß—Ç–µ–Ω–∏–µ Google Sheets –∫–∞–∫ CSV..."):
                    df_src = gs_read_csv(gs_url)
                # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ wb_sku (–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤–æ–µ –≤—Ö–æ–∂–¥–µ–Ω–∏–µ)
                df_src = gs_dedup(df_src)

                st.session_state["norm_df"] = df_src
                st.session_state["norm_errors"] = []

                st.subheader("–°–≤–æ–¥–∫–∞")
                m1, m2 = st.columns(2)
                m1.metric("–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", len(df_src))
                m2.metric("–ö–æ–ª–æ–Ω–æ–∫", len(df_src.columns))

                st.subheader("–î–∞–Ω–Ω—ã–µ (–ø—Ä–µ–≤—å—é)")
                st.dataframe(_arrow_safe(df_src.head(20)), width="stretch")

                csv_buf = io.StringIO()
                df_src.to_csv(csv_buf, index=False)
                st.download_button(
                    "–°–∫–∞—á–∞—Ç—å CSV", data=csv_buf.getvalue().encode("utf-8"), file_name="punta_google.csv", mime="text/csv"
                )
            except Exception as exc:  # noqa: BLE001
                st.exception(exc)

    with import_col:
        if st.button("–ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –ë–î", disabled="norm_df" not in st.session_state or not gs_url):
            try:
                df_ready: pd.DataFrame = st.session_state.get("norm_df", pd.DataFrame())
                if df_ready.empty:
                    st.error("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä.")
                else:
                    def _sget(key: str) -> str | None:
                        try:
                            return st.secrets[key]  # type: ignore[index]
                        except Exception:
                            return None

                    md_token = st.session_state.get("md_token") or _sget("md_token")
                    md_database = st.session_state.get("md_database") or _sget("md_database")
                    if not md_token:
                        st.warning("MD —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ù–∞—Å—Ç—Ä–æ–π–∫–∏.")

                    with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –≤ MotherDuck (–ø–æ–ª–Ω–∞—è –∑–∞–º–µ–Ω–∞)..."):
                        msg = load_dataframe(
                            df_ready,
                            table=spec.table,
                            md_token=md_token,
                            md_database=md_database,
                            replace=True,
                        )

                    # –°–æ–∑–¥–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–∞ –ø–æ wb_sku, –µ—Å–ª–∏ –∫–æ–ª–æ–Ω–∫–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                    try:
                        with get_connection(md_token=md_token, md_database=md_database) as con:
                            info = con.execute('PRAGMA table_info("punta_google")').fetch_df()
                            cols = set(info["name"].astype(str).tolist())
                            if "wb_sku" in cols:
                                con.execute(
                                    'CREATE INDEX IF NOT EXISTS idx_punta_google_wb_sku ON "punta_google" (wb_sku)'
                                )
                    except Exception:
                        # –ò–Ω–¥–µ–∫—Å –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª–µ–Ω; –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –∏–º–ø–æ—Ä—Ç
                        pass

                    st.success(msg)
            except Exception as exc:  # noqa: BLE001
                st.exception(exc)
else:
    st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –¥–ª—è –Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç—ã –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ —Å—Å—ã–ª–∫—É –Ω–∞ Google Sheets.")
