from __future__ import annotations

import io
from dataclasses import dataclass, field

import pandas as pd
import streamlit as st
from dataforge.matching import search_matches
from dataforge.ui import setup_page

setup_page(title="DataForge", icon="üõ†Ô∏è")

DEFECT_PREFIX = "–ë—Ä–∞–∫SH"

@dataclass
class MatchConfig:
    """Configuration for marketplace matching search."""

    md_token: str | None = None
    md_database: str | None = None
    filter_no_defect: bool = True
    filter_unique_sizes: bool = True
    limit_per_input: int = 0
    selected_cols: list[str] = field(default_factory=lambda: DEFAULT_COLUMNS.copy())


def get_config() -> MatchConfig:
    """Load configuration from session state and secrets."""
    return MatchConfig(
        md_token=st.session_state.get("md_token") or _sget("md_token"),
        md_database=st.session_state.get("md_database") or _sget("md_database"),
        filter_no_defect=st.session_state.get("mp_filter_no_defect", True),
        filter_unique_sizes=st.session_state.get("mp_filter_unique_sizes", True),
        limit_per_input=int(st.session_state.get("limit_per_input", 0)),
        selected_cols=st.session_state.get("mp_selected_cols", DEFAULT_COLUMNS.copy()),
    )
st.title("üîé –ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π –∫–∞—Ä—Ç–æ—á–µ–∫ (Ozon ‚Üî WB)")
st.caption(
    "–ù–∞–π–¥–∏—Ç–µ –æ–±—â–∏–µ –∫–∞—Ä—Ç–æ—á–∫–∏ –º–µ–∂–¥—É –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞–º–∏ –ø–æ —à—Ç—Ä–∏—Ö–∫–æ–¥–∞–º. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –º–∞—Å—Å–æ–≤—ã–π –≤–≤–æ–¥."
)


def _sget(key: str) -> str | None:
    try:
        return st.secrets[key]  # type: ignore[index]
    except Exception:
        return None


md_token = st.session_state.get("md_token") or _sget("md_token")
md_database = st.session_state.get("md_database") or _sget("md_database")

if "mp_filter_no_defect" not in st.session_state:
    st.session_state["mp_filter_no_defect"] = True

if "mp_filter_unique_sizes" not in st.session_state:
    st.session_state["mp_filter_unique_sizes"] = True

if not md_token:
    st.warning("MD —Ç–æ–∫–µ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ù–∞—Å—Ç—Ä–æ–π–∫–∏.")


def parse_input(text: str) -> list[str]:
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ª—é–±—ã–º –ø—Ä–æ–±–µ–ª–∞–º –∏ –ø–µ—Ä–µ–≤–æ–¥–∞–º —Å—Ç—Ä–æ–∫–∏; —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ
    tokens = [t.strip() for t in text.replace(",", " ").split()]  # –∑–∞–ø—è—Ç—ã–µ —Ç–æ–∂–µ —Å—á–∏—Ç–∞–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º
    return [t for t in tokens if t]


def _dedupe_sizes(df: pd.DataFrame, input_type: str) -> pd.DataFrame:
    """Remove duplicate sizes keeping the highest match_score per size group.

    Rules:
    - If input_type is 'wb_sku': keep unique wb_size within each wb_sku
    - If input_type is 'oz_sku' or 'oz_vendor_code': keep unique oz_manufacturer_size within each oz_sku
    - Otherwise (e.g., barcode), leave as is
    """
    if df.empty:
        return df

    if input_type == "wb_sku":
        size_col = "wb_size"
        group_cols = ["wb_sku", size_col]
    elif input_type in ("oz_sku", "oz_vendor_code"):
        size_col = "oz_manufacturer_size"
        group_cols = ["oz_sku", size_col]
    else:
        return df

    if "match_score" not in df.columns or any(col not in df.columns for col in group_cols):
        return df

    # Work only with rows where size is non-empty/non-null; keep others intact
    mask_known_size = df[size_col].notna() & (df[size_col].astype(str).str.strip() != "")
    df_known = df.loc[mask_known_size].copy()
    df_unknown = df.loc[~mask_known_size].copy()

    if df_known.empty:
        return df

    # Sort to keep the highest score first; tie-breakers stay stable
    df_known = df_known.sort_values(["match_score"], ascending=[False])
    df_known = df_known.drop_duplicates(subset=group_cols, keep="first")

    # Preserve original order as much as possible: place known first by score, then unknown
    return pd.concat([df_known, df_unknown], axis=0, ignore_index=True)


DEFAULT_COLUMNS = [
    "oz_sku",
    "oz_vendor_code",
    "oz_primary_barcode",
    "wb_sku",
    "wb_primary_barcode",
    "wb_size",
    "oz_is_primary_hit",
    "wb_is_primary_hit",
    "barcode_hit",
    "input_external_code",
    "matched_by",
    "match_score",
    # Punta
    "punta_external_code_oz",
    "punta_collection_oz",
    "punta_external_code_wb",
    "punta_collection_wb",
    "punta_external_equal",
]

ALL_COLUMNS = [
    # OZ
    "oz_sku",
    "oz_vendor_code",
    "oz_product_name",
    "oz_manufacturer_size",
    "oz_brand",
    "oz_color",
    "oz_primary_barcode",
    # WB
    "wb_sku",
    "wb_article",
    "wb_brand",
    "wb_color",
    "wb_size",
    "wb_primary_barcode",
    # Match
    "oz_is_primary_hit",
    "wb_is_primary_hit",
    "barcode_hit",
    "input_external_code",
    "matched_by",
    "match_score",
    # Punta (optional enrichment)
    "punta_external_code_oz",
    "punta_collection_oz",
    "punta_external_code_wb",
    "punta_collection_wb",
    "punta_external_equal",
]


with st.form(key="mp_match_form"):
    col1, col2 = st.columns([1, 1])
    with col1:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–ª—é—á –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ñ–æ—Ä–º—ã
        mp_input_option = st.selectbox(
            "–¢–∏–ø –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
            options=[
                ("–ê—Ä—Ç–∏–∫—É–ª Ozon (oz_sku)", "oz_sku"),
                ("–ê—Ä—Ç–∏–∫—É–ª WB (wb_sku)", "wb_sku"),
                ("–®—Ç—Ä–∏—Ö–∫–æ–¥", "barcode"),
                ("–ê—Ä—Ç–∏–∫—É–ª –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞ Ozon (oz_vendor_code)", "oz_vendor_code"),
                ("Punta external code (external_code)", "punta_external_code"),
            ],
            format_func=lambda x: x[0],
            key="mp_input_option",
        )

    with col2:
        st.number_input(
            "–õ–∏–º–∏—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (0 ‚Äî –±–µ–∑ –ª–∏–º–∏—Ç–∞)",
            min_value=0,
            max_value=10000,
            value=int(st.session_state.get("limit_per_input", 0)),
            key="limit_per_input",
        )

    st.text_area(
        "–ó–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞",
        value=st.session_state.get("mp_input_text", ""),
        height=140,
        help=(
            "–í—Å—Ç–∞–≤—å—Ç–µ —Å–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π —á–µ—Ä–µ–∑ –ø—Ä–æ–±–µ–ª –∏–ª–∏ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏. "
            "–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è 10‚Äì300+ –∑–Ω–∞—á–µ–Ω–∏–π."
        ),
        key="mp_input_text",
    )

    st.checkbox(
        "–ë–µ–∑ –±—Ä–∞–∫–∞ –û–∑–æ–Ω",
        key="mp_filter_no_defect",
        help="–ò—Å–∫–ª—é—á–∏—Ç—å –∞—Ä—Ç–∏–∫—É–ª—ã Ozon, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è –Ω–∞ ¬´–ë—Ä–∞–∫SH¬ª.",
    )

    st.checkbox(
        "–ë–µ–∑ –¥—É–±–ª–µ–π —Ä–∞–∑–º–µ—Ä–æ–≤",
        key="mp_filter_unique_sizes",
        help=(
            "–û—Å—Ç–∞–≤–ª—è—Ç—å –ø–æ –æ–¥–Ω–æ–º—É –∑–Ω–∞—á–µ–Ω–∏—é —Ä–∞–∑–º–µ—Ä–∞ —Å –Ω–∞–∏–≤—ã—Å—à–∏–º match_score "
            "–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (wb_sku –∏–ª–∏ oz_sku)."
        ),
    )

    st.multiselect(
        "–ü–æ–ª—è –¥–ª—è –≤—ã–≤–æ–¥–∞",
        options=ALL_COLUMNS,
        default=st.session_state.get("mp_selected_cols", DEFAULT_COLUMNS),
        help="–ú–æ–∂–Ω–æ –º–µ–Ω—è—Ç—å –Ω–∞–±–æ—Ä –∫–æ–ª–æ–Ω–æ–∫ –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞.",
        key="mp_selected_cols",
    )

    submitted = st.form_submit_button("–ù–∞–π—Ç–∏", type="primary")

if submitted:
    # –ß–∏—Ç–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ session_state –ø–æ—Å–ª–µ submit ‚Äî –∏–Ω–∞—á–µ –±–µ—Ä—ë—Ç—Å—è –ø—Ä–µ–¥—ã–¥—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    input_type = st.session_state.get("mp_input_option", (None, ""))[1]
    text_value = st.session_state.get("mp_input_text", "")
    limit_per_input = int(st.session_state.get("limit_per_input", 0))

    values = parse_input(text_value)
    if not values:
        st.warning("–í–≤–µ–¥–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞.")
        st.stop()

    if len(values) > 300:
        st.info(
            f"–ü–µ—Ä–µ–¥–∞–Ω–æ {len(values)} –∑–Ω–∞—á–µ–Ω–∏–π. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è, –¥–æ–∂–¥–∏—Ç–µ—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è."
        )

    if not md_token:
        st.error("MD —Ç–æ–∫–µ–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç. –£–∫–∞–∂–∏—Ç–µ –µ–≥–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ù–∞—Å—Ç—Ä–æ–π–∫–∏.")
        st.stop()

    try:
        with st.spinner("–ü–æ–∏—Å–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π..."):
            df_res = search_matches(
                values,
                input_type=input_type,
                limit_per_input=(None if int(limit_per_input) <= 0 else int(limit_per_input)),
                md_token=md_token,
                md_database=md_database,
            )
        # Apply filters immediately
        filter_no_defect = st.session_state.get("mp_filter_no_defect", True)
        if filter_no_defect and "oz_vendor_code" in df_res.columns:
            starts_with_brak = (
                df_res["oz_vendor_code"].fillna("").astype(str).str.startswith(DEFECT_PREFIX)
            )
            df_res = df_res.loc[~starts_with_brak]

        # Apply deduplication before storing
        if st.session_state.get("mp_filter_unique_sizes", True):
            df_res = _dedupe_sizes(df_res, input_type=input_type)

        st.session_state["mp_match_result"] = df_res
        st.session_state["mp_input_type"] = input_type
    except ValueError as exc:
        st.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {exc}")
    except (ConnectionError, TimeoutError) as exc:
        st.error(f"üîå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö: {exc}")
    except Exception as exc:
        st.error("‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π:")
        st.exception(exc)


df_show: pd.DataFrame = st.session_state.get("mp_match_result", pd.DataFrame())

if df_show.empty:
    st.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç –ø–æ–∫–∞–∑–∞–Ω—ã –∑–¥–µ—Å—å –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–∫–∏ ‚Äò–ù–∞–π—Ç–∏‚Äô.")
    st.stop()

# –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∫–æ–ª–æ–Ω–∫–∏ (–µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç, –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º)
cols_to_show = [c for c in st.session_state.get("mp_selected_cols", DEFAULT_COLUMNS) if c in df_show.columns]
if not cols_to_show:
    cols_to_show = [c for c in DEFAULT_COLUMNS if c in df_show.columns]

st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
m1, m2 = st.columns(2)
with m1:
    st.metric("–í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫", len(df_show))
with m2:
    st.metric("–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —à—Ç—Ä–∏—Ö–∫–æ–¥–æ–≤", df_show["barcode_hit"].nunique() if "barcode_hit" in df_show else 0)

st.dataframe(df_show[cols_to_show], width="stretch", height=600)

csv_buf = io.StringIO()
df_show[cols_to_show].to_csv(csv_buf, index=False)
st.download_button(
    "–°–∫–∞—á–∞—Ç—å CSV",
    data=csv_buf.getvalue().encode("utf-8"),
    file_name="mp_matches.csv",
    mime="text/csv",
)
